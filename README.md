
---

# Search Scraper GUI

> **A Python-based application to scrape search engine results efficiently with a user-friendly GUI.**

## ğŸš€ Features

- **Advanced Search Operators**: Use operators like `site:`, `inurl:`, `intitle:`, and more.
- **Multi-Engine Support**: Scrape results from Bing, DuckDuckGo, Yahoo, and Mojeek.
- **Duplicate Removal**: Automatically clean up duplicate entries for better data.
- **Output Formats**: Save results in `.csv` or `.xlsx` formats.
- **User-Friendly Interface**: Intuitive GUI powered by `tkinter`.
- **Logging and Debugging**: Track scraping progress and errors in detailed logs.
- **Dark Theme**: Stylish and comfortable interface for extended use.

---

## ğŸ› ï¸ Installation

### Prerequisites

- **Python 3.7+** is required.  
- Install dependencies using pip:

```bash
pip install -r requirements.txt
```

### Required Libraries
The following Python packages are required:
- `tkinter`
- `pandas`
- `openpyxl`
- `beautifulsoup4`
- `requests`

---

## ğŸš¦ Usage

### Clone the Repository
```bash
git clone https://github.com/Dunamisss/search-scraper-gui.git
cd search-scraper-gui
```

### Run the Application
```bash
python main.py
```

### Using the GUI
1. Enter your **Search Query** in the input field.
2. Specify the number of results per search engine.
3. Choose the output format (`CSV` or `XLSX`) from the dropdown.
4. Click **Start Scraping** to begin.
5. Monitor progress in the **log panel** and progress bar.
6. Scraped data will be saved in the `results/` directory.

---

## ğŸ“œ License

This project is licensed under the **MIT License**. See the [LICENSE](LICENSE) file for more details.

---



---

### Contributing:

We welcome contributions!  If you have suggestions, bug reports, or feature requests, please open an issue or submit a pull request.  Your help in improving this project is greatly appreciated.
Let me know if you'd like to add anything else or need help configuring the repository further!

